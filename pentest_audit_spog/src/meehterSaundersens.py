import os
import json
import requests
import logging
import pandas as pd
import sys
import argparse  # Import argparse for CLI arguments
from pathlib import Path
from openpyxl import load_workbook
from docx import Document
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor
from colorama import Fore, Style  # For color-coded CLI output

# Setup logging for debugging and audit trail
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[logging.FileHandler("audit_log.log"), logging.StreamHandler()]
)

# Load API token securely from a config.json file
try:
    with open("config.json") as f:
        config = json.load(f)
    ARCHER_HEADERS = {"Authorization": f"Bearer {config['API_TOKEN']}"}
except Exception as e:
    logging.error("Failed to load API credentials: %s", e)
    ARCHER_HEADERS = {"Authorization": "Bearer DUMMY_TOKEN"}  # Fallback for testing

# Base path for Ethical Hacking SOW folders
BASE_PATH = Path("/path/to/Ethical_Hacks/2024/")  # Update as needed
REQUIRED_FOLDERS = {"NVA", "REQUESTINFO", "REPORTS"}  # Required folders inside each SOW

# Function to apply color to CLI output for better readability
def colorize_status(status):
    if "Mismatch" in status:
        return f"{Fore.RED}{status}{Style.RESET_ALL}"  # Red for errors
    elif "Missing" in status:
        return f"{Fore.YELLOW}{status}{Style.RESET_ALL}"  # Yellow for missing files
    else:
        return f"{Fore.GREEN}{status}{Style.RESET_ALL}"  # Green for success

# Fetch Archer Data (This would be a real API call in production)
def fetch_archer_data(sow_id):
    try:
        response = {
            "sow_id": sow_id,
            "status": "Completed",
            "testers": ["Tester1", "Tester2"],
            "findings": {"Finding A": "High", "Finding B": "Medium"},
            "report_status": "Preliminary",  # Dummy status
            "report_date": "2024-02-01",  # Dummy date
        }
        return response
    except Exception as e:
        logging.error(f"Error fetching Archer data for {sow_id}: {e}")
        return None

# Validate if required folders exist in each SOW
def validate_sow_structure(sow_folder):
    try:
        found_folders = {p.name for p in sow_folder.iterdir() if p.is_dir()}
        missing_folders = REQUIRED_FOLDERS - found_folders
        return "Valid" if not missing_folders else f"Missing: {', '.join(missing_folders)}"
    except Exception as e:
        logging.error(f"Error validating folder structure for {sow_folder}: {e}")
        return "Error"

# Perform audit on a single SOW
def audit_sow(sow_folder, status_filter, start_date, end_date):
    sow_id = sow_folder.name
    archer_data = fetch_archer_data(sow_id)
    if not archer_data:
        return {"SOW ID": sow_id, "Error": "Failed to fetch Archer data"}

    # Apply status and date range filtering
    report_status = archer_data.get("report_status", "Unknown")
    report_date = archer_data.get("report_date", "0000-00-00")
    
    if status_filter and report_status.lower() != status_filter.lower():
        return None  # Skip this SOW if status doesn't match
    
    if start_date and end_date:
        report_datetime = datetime.strptime(report_date, "%Y-%m-%d")
        if not (start_date <= report_datetime <= end_date):
            return None  # Skip if outside date range

    structure_status = validate_sow_structure(sow_folder)
    return {
        "SOW ID": sow_id,
        "Structure": structure_status,
        "Report Status": report_status,
        "Report Date": report_date,
    }

# Run audits in parallel
def run_audit(month="*", status=None, start_date=None, end_date=None):
    sow_folders = list(BASE_PATH.glob(f"SOW_*_{month}*"))
    audit_results = []
    
    if start_date and end_date:
        start_date = datetime.strptime(start_date, "%Y-%m-%d")
        end_date = datetime.strptime(end_date, "%Y-%m-%d")
    
    with ThreadPoolExecutor(max_workers=5) as executor:
        results = executor.map(lambda folder: audit_sow(folder, status, start_date, end_date), sow_folders)
        audit_results = [r for r in results if r]
    
    return audit_results

# Argument Parser for CLI mode
parser = argparse.ArgumentParser(description="Ethical Hack Audit Tool")
parser.add_argument("--month", type=str, help="Specify month (MM format) or 'all' for full scan")
parser.add_argument("--status", type=str, choices=["prelim", "final"], help="Filter by report status")
parser.add_argument("--start-date", type=str, help="Start date (YYYY-MM-DD)")
parser.add_argument("--end-date", type=str, help="End date (YYYY-MM-DD)")
parser.add_argument("--export", action="store_true", help="Export results to JSON & Excel")
args = parser.parse_args()

# Run interactive or non-interactive mode
def main():
    results = run_audit(args.month if args.month else "*", args.status, args.start_date, args.end_date)
    print_audit_summary(results)
    if args.export:
        export_results(results)

# Run the tool
if __name__ == "__main__":
    main()
